2024-05-27 12:15:47,364 [INFO] Working on machine_name='ares'
2024-05-27 12:15:47,377 [INFO] device='cuda'
2024-05-27 12:15:47,377 [INFO] experiment_dir='ResNet18_attacker=L1ProjectedGradientDescent_epsilon=0.01'
2024-05-27 12:15:47,377 [INFO] train_path='../data/german/detect_attack/ResNet18_attacker=L1ProjectedGradientDescent_epsilon=0.01/train'
2024-05-27 12:15:47,377 [INFO] test_path='../data/german/detect_attack/ResNet18_attacker=L1ProjectedGradientDescent_epsilon=0.01/test'
2024-05-27 12:15:47,377 [INFO] epochs=1000 batch_size= 160 lr= 0.001 model_type= 'resnet50' difference=0 
2024-05-27 12:15:47,644 [INFO] Model name: resnet.ResNet
2024-05-27 12:15:47,644 [INFO] ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer2): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer3): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (4): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (5): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer4): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=2048, out_features=2, bias=True)
)
2024-05-27 12:15:47,648 [INFO] =================================================================
Layer (type:depth-idx)                   Param #
=================================================================
ResNet                                   --
├─Conv2d: 1-1                            9,408
├─BatchNorm2d: 1-2                       128
├─ReLU: 1-3                              --
├─MaxPool2d: 1-4                         --
├─Sequential: 1-5                        --
│    └─Bottleneck: 2-1                   --
│    │    └─Conv2d: 3-1                  4,096
│    │    └─BatchNorm2d: 3-2             128
│    │    └─Conv2d: 3-3                  36,864
│    │    └─BatchNorm2d: 3-4             128
│    │    └─Conv2d: 3-5                  16,384
│    │    └─BatchNorm2d: 3-6             512
│    │    └─ReLU: 3-7                    --
│    │    └─Sequential: 3-8              16,896
│    └─Bottleneck: 2-2                   --
│    │    └─Conv2d: 3-9                  16,384
│    │    └─BatchNorm2d: 3-10            128
│    │    └─Conv2d: 3-11                 36,864
│    │    └─BatchNorm2d: 3-12            128
│    │    └─Conv2d: 3-13                 16,384
│    │    └─BatchNorm2d: 3-14            512
│    │    └─ReLU: 3-15                   --
│    └─Bottleneck: 2-3                   --
│    │    └─Conv2d: 3-16                 16,384
│    │    └─BatchNorm2d: 3-17            128
│    │    └─Conv2d: 3-18                 36,864
│    │    └─BatchNorm2d: 3-19            128
│    │    └─Conv2d: 3-20                 16,384
│    │    └─BatchNorm2d: 3-21            512
│    │    └─ReLU: 3-22                   --
├─Sequential: 1-6                        --
│    └─Bottleneck: 2-4                   --
│    │    └─Conv2d: 3-23                 32,768
│    │    └─BatchNorm2d: 3-24            256
│    │    └─Conv2d: 3-25                 147,456
│    │    └─BatchNorm2d: 3-26            256
│    │    └─Conv2d: 3-27                 65,536
│    │    └─BatchNorm2d: 3-28            1,024
│    │    └─ReLU: 3-29                   --
│    │    └─Sequential: 3-30             132,096
│    └─Bottleneck: 2-5                   --
│    │    └─Conv2d: 3-31                 65,536
│    │    └─BatchNorm2d: 3-32            256
│    │    └─Conv2d: 3-33                 147,456
│    │    └─BatchNorm2d: 3-34            256
│    │    └─Conv2d: 3-35                 65,536
│    │    └─BatchNorm2d: 3-36            1,024
│    │    └─ReLU: 3-37                   --
│    └─Bottleneck: 2-6                   --
│    │    └─Conv2d: 3-38                 65,536
│    │    └─BatchNorm2d: 3-39            256
│    │    └─Conv2d: 3-40                 147,456
│    │    └─BatchNorm2d: 3-41            256
│    │    └─Conv2d: 3-42                 65,536
│    │    └─BatchNorm2d: 3-43            1,024
│    │    └─ReLU: 3-44                   --
│    └─Bottleneck: 2-7                   --
│    │    └─Conv2d: 3-45                 65,536
│    │    └─BatchNorm2d: 3-46            256
│    │    └─Conv2d: 3-47                 147,456
│    │    └─BatchNorm2d: 3-48            256
│    │    └─Conv2d: 3-49                 65,536
│    │    └─BatchNorm2d: 3-50            1,024
│    │    └─ReLU: 3-51                   --
├─Sequential: 1-7                        --
│    └─Bottleneck: 2-8                   --
│    │    └─Conv2d: 3-52                 131,072
│    │    └─BatchNorm2d: 3-53            512
│    │    └─Conv2d: 3-54                 589,824
│    │    └─BatchNorm2d: 3-55            512
│    │    └─Conv2d: 3-56                 262,144
│    │    └─BatchNorm2d: 3-57            2,048
│    │    └─ReLU: 3-58                   --
│    │    └─Sequential: 3-59             526,336
│    └─Bottleneck: 2-9                   --
│    │    └─Conv2d: 3-60                 262,144
│    │    └─BatchNorm2d: 3-61            512
│    │    └─Conv2d: 3-62                 589,824
│    │    └─BatchNorm2d: 3-63            512
│    │    └─Conv2d: 3-64                 262,144
│    │    └─BatchNorm2d: 3-65            2,048
│    │    └─ReLU: 3-66                   --
│    └─Bottleneck: 2-10                  --
│    │    └─Conv2d: 3-67                 262,144
│    │    └─BatchNorm2d: 3-68            512
│    │    └─Conv2d: 3-69                 589,824
│    │    └─BatchNorm2d: 3-70            512
│    │    └─Conv2d: 3-71                 262,144
│    │    └─BatchNorm2d: 3-72            2,048
│    │    └─ReLU: 3-73                   --
│    └─Bottleneck: 2-11                  --
│    │    └─Conv2d: 3-74                 262,144
│    │    └─BatchNorm2d: 3-75            512
│    │    └─Conv2d: 3-76                 589,824
│    │    └─BatchNorm2d: 3-77            512
│    │    └─Conv2d: 3-78                 262,144
│    │    └─BatchNorm2d: 3-79            2,048
│    │    └─ReLU: 3-80                   --
│    └─Bottleneck: 2-12                  --
│    │    └─Conv2d: 3-81                 262,144
│    │    └─BatchNorm2d: 3-82            512
│    │    └─Conv2d: 3-83                 589,824
│    │    └─BatchNorm2d: 3-84            512
│    │    └─Conv2d: 3-85                 262,144
│    │    └─BatchNorm2d: 3-86            2,048
│    │    └─ReLU: 3-87                   --
│    └─Bottleneck: 2-13                  --
│    │    └─Conv2d: 3-88                 262,144
│    │    └─BatchNorm2d: 3-89            512
│    │    └─Conv2d: 3-90                 589,824
│    │    └─BatchNorm2d: 3-91            512
│    │    └─Conv2d: 3-92                 262,144
│    │    └─BatchNorm2d: 3-93            2,048
│    │    └─ReLU: 3-94                   --
├─Sequential: 1-8                        --
│    └─Bottleneck: 2-14                  --
│    │    └─Conv2d: 3-95                 524,288
│    │    └─BatchNorm2d: 3-96            1,024
│    │    └─Conv2d: 3-97                 2,359,296
│    │    └─BatchNorm2d: 3-98            1,024
│    │    └─Conv2d: 3-99                 1,048,576
│    │    └─BatchNorm2d: 3-100           4,096
│    │    └─ReLU: 3-101                  --
│    │    └─Sequential: 3-102            2,101,248
│    └─Bottleneck: 2-15                  --
│    │    └─Conv2d: 3-103                1,048,576
│    │    └─BatchNorm2d: 3-104           1,024
│    │    └─Conv2d: 3-105                2,359,296
│    │    └─BatchNorm2d: 3-106           1,024
│    │    └─Conv2d: 3-107                1,048,576
│    │    └─BatchNorm2d: 3-108           4,096
│    │    └─ReLU: 3-109                  --
│    └─Bottleneck: 2-16                  --
│    │    └─Conv2d: 3-110                1,048,576
│    │    └─BatchNorm2d: 3-111           1,024
│    │    └─Conv2d: 3-112                2,359,296
│    │    └─BatchNorm2d: 3-113           1,024
│    │    └─Conv2d: 3-114                1,048,576
│    │    └─BatchNorm2d: 3-115           4,096
│    │    └─ReLU: 3-116                  --
├─AdaptiveAvgPool2d: 1-9                 --
├─Linear: 1-10                           4,098
=================================================================
Total params: 23,512,130
Trainable params: 23,512,130
Non-trainable params: 0
=================================================================
2024-05-27 12:15:47,649 [INFO] Optimizer: Adam
2024-05-27 12:15:47,649 [INFO] Scheduler: lr_scheduler.StepLR, step_size=10, gamma=0.9
2024-05-27 12:15:48,565 [INFO] Getting mean and std...
2024-05-27 12:23:37,960 [INFO] scheduled lr=[0.001]
2024-05-27 12:23:37,960 [INFO] Average running loss at epoch 1/1000: 0.00026347385493292514
2024-05-27 12:25:35,718 [INFO] Average train loss at epoch 1/1000: 0.0051482535116393014
2024-05-27 12:31:04,510 [INFO] scheduled lr=[0.001]
2024-05-27 12:31:04,511 [INFO] Average running loss at epoch 2/1000: 0.0001464496906184027
2024-05-27 12:33:02,253 [INFO] Average train loss at epoch 2/1000: 0.2744568844941251
2024-05-27 12:38:30,900 [INFO] scheduled lr=[0.001]
2024-05-27 12:38:30,901 [INFO] Average running loss at epoch 3/1000: 0.00016322206500170457
2024-05-27 12:40:28,659 [INFO] Average train loss at epoch 3/1000: 0.07406198870891932
2024-05-27 12:45:57,355 [INFO] scheduled lr=[0.001]
2024-05-27 12:45:57,355 [INFO] Average running loss at epoch 4/1000: 5.043924196388823e-05
2024-05-27 12:47:55,073 [INFO] Average train loss at epoch 4/1000: 0.09192698922558423
2024-05-27 12:53:23,957 [INFO] scheduled lr=[0.001]
2024-05-27 12:53:23,957 [INFO] Average running loss at epoch 5/1000: 6.039463449670944e-05
2024-05-27 12:55:21,727 [INFO] Average train loss at epoch 5/1000: 6.688811784099076e-05
2024-05-27 12:57:19,617 [INFO] Train accuracy/Train at epoch 5: 0.9956769853667867
2024-05-27 12:59:32,936 [INFO] Test accuracy/Train at epoch 5: 0.9950777862790104
2024-05-27 13:05:02,052 [INFO] scheduled lr=[0.001]
2024-05-27 13:05:02,053 [INFO] Average running loss at epoch 6/1000: 0.00014932183535894183
2024-05-27 13:06:59,644 [INFO] Average train loss at epoch 6/1000: 0.1111461947042681
2024-05-27 13:12:28,252 [INFO] scheduled lr=[0.001]
2024-05-27 13:12:28,253 [INFO] Average running loss at epoch 7/1000: 8.153895184086615e-05
2024-05-27 13:14:25,889 [INFO] Average train loss at epoch 7/1000: 0.03984921329809416
2024-05-27 13:19:54,656 [INFO] scheduled lr=[0.001]
2024-05-27 13:19:54,657 [INFO] Average running loss at epoch 8/1000: 6.001438567835718e-05
2024-05-27 13:21:52,303 [INFO] Average train loss at epoch 8/1000: 0.19770175954957592
2024-05-27 13:27:20,993 [INFO] scheduled lr=[0.001]
2024-05-27 13:27:20,994 [INFO] Average running loss at epoch 9/1000: 4.123517065974868e-05
2024-05-27 13:29:18,743 [INFO] Average train loss at epoch 9/1000: 0.031619813528280465
2024-05-27 13:34:47,508 [INFO] scheduled lr=[0.0009000000000000001]
2024-05-27 13:34:47,508 [INFO] Average running loss at epoch 10/1000: 5.255764194753931e-05
